{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "import skvideo.io\n",
    "import cv2\n",
    "import json\n",
    "import random\n",
    "\n",
    "from keras.models import Sequential,model_from_json\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import sgd, Adam\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D, Reshape, BatchNormalization\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MiniProject #3: Deep Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
    "\n",
    "\\begin{equation*}\n",
    "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
    "\\end{equation*}\n",
    "\n",
    "where: \n",
    "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "We note the $Q$-function:\n",
    "\n",
    "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "Thus, the optimal Q function is:\n",
    "\\begin{equation*}\n",
    "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The environment, the agent and the game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def act(self, act):\n",
    "        \"\"\"\n",
    "        One can act on the environment and obtain its reaction:\n",
    "        - the new state\n",
    "        - the reward of the new state\n",
    "        - should we continue the game?\n",
    "\n",
    "        :return: state, reward, game_over\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reinitialize the environment to a random state and returns\n",
    "        the original state\n",
    "\n",
    "        :return: state\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def draw(self):\n",
    "        \"\"\"\n",
    "        Visualize in the console or graphically the current state\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
    "\n",
    "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
    "\n",
    "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
    "\n",
    "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self, epsilon=0.1, n_action=4):\n",
    "        self.epsilon = epsilon\n",
    "        self.n_action = n_action\n",
    "    \n",
    "    def set_epsilon(self,e):\n",
    "        self.epsilon = e\n",
    "\n",
    "    def act(self, s, train=True):\n",
    "        \"\"\" This function should return the next action to do:\n",
    "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
    "        if train:\n",
    "            if np.random.rand() <= self.epsilon:\n",
    "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
    "            else:\n",
    "                a = self.learned_act(s)\n",
    "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
    "            a = self.learned_act(s)\n",
    "\n",
    "        return a\n",
    "\n",
    "    def learned_act(self, s):\n",
    "        \"\"\" Act via the policy of the agent, from a given state s\n",
    "        it proposes an action a\"\"\"\n",
    "        pass\n",
    "\n",
    "    def reinforce(self, s, n_s, a, r, game_over_):\n",
    "        \"\"\" This function is the core of the learning algorithm. \n",
    "        It takes as an input the current state s_, the next state n_s_\n",
    "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
    "        \n",
    "        Its goal is to learn a policy.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\" This function returns basic stats if applicable: the\n",
    "        loss and/or the model\"\"\"\n",
    "        pass\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\" This function allows to restore a model\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 1__:\n",
    "Explain the function act. Why is ```epsilon``` essential?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The method `Agent.act(state, train=True)` is where the agent is deciding what to do. It takes the current state of the environment as an input (`state`) and tries to predict the action to perform.\n",
    ">\n",
    "> However, the agent needs to learn what is the best action to perform. At the first time step, the agent has no idea what it supposed to do. Inspired by trial and error, in reinforcement learning, the agent has to experiment new behaviors to find the one the most rewarding: which yields the greated expected cumulative reward (or expected return $R(\\pi)$).\n",
    ">\n",
    "> This trial and error behavior is called the exploration/exploitation policy and the most common one, is the $\\varepsilon$-greedy (`Agent.epsilon`) exploration policy. With some probibility $\\varepsilon$, the agent will explore (draw an action at random) and otherwise, it will exploit the policy that it has learned.\n",
    ">\n",
    "> This way, the agent needs to explore greatly in the early stages, then decrease the $\\varepsilon$ value to use the knowledge acquired until now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### The Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
    "\n",
    "```python\n",
    "\n",
    "epoch = 300\n",
    "env = Environment()\n",
    "agent = Agent()\n",
    "\n",
    "\n",
    "# Number of won games\n",
    "score = 0\n",
    "loss = 0\n",
    "\n",
    "\n",
    "for e in range(epoch):\n",
    "    # At each epoch, we restart to a fresh game and get the initial state\n",
    "    state = env.reset()\n",
    "    # This assumes that the games will end\n",
    "    game_over = False\n",
    "\n",
    "    win = 0\n",
    "    lose = 0\n",
    "    \n",
    "    while not game_over:\n",
    "        # The agent performs an action\n",
    "        action = agent.act(state)\n",
    "\n",
    "        # Apply an action to the environment, get the next state, the reward\n",
    "        # and if the games end\n",
    "        prev_state = state\n",
    "        state, reward, game_over = env.act(action)\n",
    "\n",
    "        # Update the counters\n",
    "        if reward > 0:\n",
    "            win = win + reward\n",
    "        if reward < 0:\n",
    "            lose = lose -reward\n",
    "\n",
    "        # Apply the reinforcement strategy\n",
    "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "    # Save as a mp4\n",
    "    if e % 10 == 0:\n",
    "        env.draw(e)\n",
    "\n",
    "    # Update stats\n",
    "    score += win-lose\n",
    "\n",
    "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "          .format(e, epoch, loss, win, lose, win-lose))\n",
    "    agent.save()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The game, *eat cheese*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
    "\n",
    "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
    "        grid_size = grid_size+4\n",
    "        self.grid_size = grid_size\n",
    "        self.max_time = max_time\n",
    "        self.temperature = temperature\n",
    "\n",
    "        #board on which one plays\n",
    "        self.board = np.zeros((grid_size,grid_size))\n",
    "        self.position = np.zeros((grid_size,grid_size))\n",
    "\n",
    "        # coordinate of the cat\n",
    "        self.x = 0\n",
    "        self.y = 1\n",
    "\n",
    "        # self time\n",
    "        self.t = 0\n",
    "\n",
    "        self.scale=16\n",
    "\n",
    "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "    def draw(self,e):\n",
    "        skvideo.io.vwrite(\"vid/\" + str(e) + '.mp4', self.to_draw)\n",
    "\n",
    "    def get_frame(self,t):\n",
    "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
    "        b[self.board>0,0] = 256\n",
    "        b[self.board < 0, 2] = 256\n",
    "        b[self.x,self.y,:]=256\n",
    "        b[-2:,:,:]=0\n",
    "        b[:,-2:,:]=0\n",
    "        b[:2,:,:]=0\n",
    "        b[:,:2,:]=0\n",
    "        \n",
    "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        self.to_draw[t,:,:,:]=b\n",
    "\n",
    "\n",
    "    def act(self, action):\n",
    "        \"\"\"This function returns the new state, reward and decides if the\n",
    "        game ends.\"\"\"\n",
    "\n",
    "        self.get_frame(int(self.t))\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "\n",
    "        self.position[self.x, self.y] = 1\n",
    "        if action == 0:  # Right\n",
    "            if self.x == self.grid_size-3:\n",
    "                self.x = self.x-1\n",
    "            else:\n",
    "                self.x = self.x + 1\n",
    "        elif action == 1:  # Left\n",
    "            if self.x == 2:\n",
    "                self.x = self.x+1\n",
    "            else:\n",
    "                self.x = self.x-1\n",
    "        elif action == 2:  # Up\n",
    "            if self.y == self.grid_size - 3:\n",
    "                self.y = self.y - 1\n",
    "            else:\n",
    "                self.y = self.y + 1\n",
    "        elif action == 3:  # Down\n",
    "            if self.y == 2:\n",
    "                self.y = self.y + 1\n",
    "            else:\n",
    "                self.y = self.y - 1\n",
    "        else:\n",
    "            RuntimeError('Error: action not recognized')\n",
    "\n",
    "        self.t = self.t + 1\n",
    "        reward = self.board[self.x, self.y]\n",
    "        self.board[self.x, self.y] = 0\n",
    "        game_over = self.t > self.max_time\n",
    "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
    "\n",
    "        return state, reward, game_over\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
    "\n",
    "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "\n",
    "\n",
    "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
    "\n",
    "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
    "\n",
    "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "        malus[bonus>0]=0\n",
    "\n",
    "        self.board = bonus + malus\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.board[self.x,self.y] = 0\n",
    "        self.t = 0\n",
    "\n",
    "        state = np.concatenate((\n",
    "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "\n",
    "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following elements are important because they correspond to the hyper parameters for this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "size = 13\n",
    "T=200\n",
    "temperature=0.3\n",
    "epochs_train=50 # set small when debugging\n",
    "epochs_test=11 # set small when debugging\n",
    "\n",
    "# display videos\n",
    "def display_videos(name):\n",
    "    video = io.open(\"vid/\" + name, 'r+b').read()\n",
    "    encoded = base64.b64encode(video)\n",
    "    return '''<video alt=\"test\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The array `board` represents the poison and food in the game. It can also be viewed as the reward attributed to each position on the board for the agent.\n",
    ">\n",
    "> The `position` array represents the topology of the board: -1 on the sides to prevent the rat from going out of the board.\n",
    ">\n",
    "> The state is the combination of the two for a view radius of 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent(Agent):\n",
    "    def __init__(self):\n",
    "        super(RandomAgent, self).__init__()\n",
    "        pass\n",
    "\n",
    "    def learned_act(self, s, train=True):\n",
    "        return np.random.randint(0, 4, size=1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(agent,env,epochs,prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "        \n",
    "    for e in range(epochs):\n",
    "        \n",
    "         # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will end\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "\n",
    "        while not game_over:\n",
    "            # The agent performs an action\n",
    "            action = agent.act(state, train=False)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "        \n",
    "        # Save as a mp4\n",
    "        env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score = score + win-lose\n",
    "\n",
    "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
    "              .format(win, lose, score/(1+e)))\n",
    "    print('Final score: '+str(score/epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win/lose count 6.5/17.0. Average score (-10.5)\n",
      "Win/lose count 12.5/19.0. Average score (-8.5)\n",
      "Win/lose count 13.5/15.0. Average score (-6.166666666666667)\n",
      "Win/lose count 8.5/16.0. Average score (-6.5)\n",
      "Win/lose count 8.0/17.0. Average score (-7.0)\n",
      "Win/lose count 9.0/15.0. Average score (-6.833333333333333)\n",
      "Win/lose count 9.5/22.0. Average score (-7.642857142857143)\n",
      "Win/lose count 9.5/22.0. Average score (-8.25)\n",
      "Win/lose count 9.5/12.0. Average score (-7.611111111111111)\n",
      "Win/lose count 6.5/10.0. Average score (-7.2)\n",
      "Win/lose count 7.0/13.0. Average score (-7.090909090909091)\n",
      "Final score: -7.090909090909091\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the game\n",
    "env = Environment(grid_size=size, max_time=T,temperature=temperature)\n",
    "\n",
    "# Initialize the agent!\n",
    "agent = RandomAgent()\n",
    "\n",
    "test(agent,env,epochs_test,prefix='random')\n",
    "HTML(display_videos('random0.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us assume here that $T=\\infty$.\n",
    "\n",
    "***\n",
    "__Question 5__ Let $\\pi$ be a policy, show that:\n",
    "\n",
    "\\begin{equation*}\n",
    "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
    "\\end{equation*}\n",
    "\n",
    "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
    "\n",
    "\\begin{equation*}\n",
    "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
    "\\end{equation*}\n",
    "Finally, deduce that a plausible objective is:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
    "\\end{equation*}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Here, we show that $Q^{\\pi}$ follows the Bellman equation:\n",
    ">\n",
    "> \n",
    "> \\begin{equation*}\n",
    " \\begin{aligned}\n",
    "Q^{\\pi}(s, a) &= \\mathbb{E}(\\sum_{t \\le T} \\gamma^t r(s_t, a_t) | s_0 = s, a_0 = a, \\cdots, a_t=\\pi(s_t)) \\\\\n",
    "            &= r(s, a) + \\mathbb{E}(\\sum_{1 \\le t \\le T} \\gamma^t r(s_t, \\pi(a_t)) | s_0 = s, a_0 = a)\n",
    "\\end{aligned}\n",
    "\\end{equation*}\n",
    ">\n",
    "> Then using the law of total expectations:\n",
    ">\n",
    "> \n",
    ">\\begin{equation*}\n",
    "\\begin{aligned}\n",
    "Q^{\\pi}(s, a) &= r(s, a) + \\gamma \\sum_{s', a'} \\mathbb{P}(s_1 = s', a_1 = a'| s_0 = s, a_0 = a)\\mathbb{E}(\\sum_{1 \\le t \\le T} \\gamma^{t-1} r(s_t, \\pi(s_t)) | s_1 = s', a_1 = a', \\pi) \\\\\n",
    "               &= E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
    "\\end{aligned}\n",
    "\\end{equation*}\n",
    "> \n",
    "> Fo the second inequatily, we use the fact that $Q^* = \\max_{\\pi}Q^\\pi$ and, with similar derivations:\n",
    ">\n",
    ">\\begin{equation*}\n",
    "\\begin{aligned}\n",
    "Q^*(s, a) &= r(s, a) + \\gamma \\sum_{s'} \\max_{a'} \\mathbb{P}(s_1 = s', a_1 = a'| s_0 = s, a_0 = a)\\mathbb{E}(\\sum_{1 \\le t \\le T} \\gamma^{t-1} r(s_t, \\pi^*(s_t)) | s_1 = s', a_1 = a', \\pi^*) \\\\\n",
    "               &= E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma \\max_{a'}Q^*(s',a')]\n",
    "\\end{aligned}\n",
    "\\end{equation*}\n",
    ">\n",
    "> The learning problem is translated into finding the optimal policy $\\pi^*$. Instead of looking directly for its value, we look for the optimal action-value function $Q^*$.\n",
    ">\n",
    "> Using the fact that the optimal Bellman operator admits a fixed point which is $Q^*$, we can deduce that\n",
    "> $\\mathcal{L}$ is a correct loss and represent the temporal difference between $Q_t$ and $Q_{t+1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
    "\n",
    "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
    "\n",
    "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
    "\n",
    "3. Store $(s_t,a_t,s_{t+1})$;\n",
    "\n",
    "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
    "\n",
    "***\n",
    "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory(object):\n",
    "    def __init__(self, max_memory=100):\n",
    "        self.max_memory = max_memory\n",
    "        self.memory = list()\n",
    "\n",
    "    def remember(self, m):\n",
    "        if len(self.memory) == self.max_memory:\n",
    "            self.memory.pop(0)\n",
    "        self.memory.append(m)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "        \n",
    "    def random_access(self):\n",
    "        return random.sample(self.memory, 1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "The pipeline we will use for training is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(agent,env,epoch,prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "    loss = 0\n",
    "\n",
    "    for e in range(epoch):\n",
    "        # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will terminate\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "\n",
    "        while not game_over:\n",
    "            # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "\n",
    "            # Apply the reinforcement strategy\n",
    "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "        # Save as a mp4\n",
    "        if e % 10 == 0:\n",
    "            env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score += win-lose\n",
    "\n",
    "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "              .format(e, epoch, loss, win, lose, win-lose))\n",
    "        agent.save(name_weights=\"models/\" + prefix+'model.h5',name_model=\"models/\" + prefix+'model.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(Agent):\n",
    "    def __init__(self, grid_size,  epsilon = 0.1, memory_size=100, batch_size = 16,n_state=2):\n",
    "        super(DQN, self).__init__(epsilon = epsilon)\n",
    "\n",
    "        # Discount for Q learning\n",
    "        self.discount = 0.99\n",
    "        \n",
    "        self.grid_size = grid_size\n",
    "        \n",
    "        # number of state\n",
    "        self.n_state = n_state\n",
    "\n",
    "        # Memory\n",
    "        self.memory = Memory(memory_size)\n",
    "        \n",
    "        # Batch size when learning\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def learned_act(self, s):\n",
    "        s = np.expand_dims(s, axis=0)\n",
    "        y = self.model.predict(s, batch_size=1)[0]\n",
    "        return np.argmax(y)\n",
    "\n",
    "    def reinforce(self, s_, n_s_, a_, r_, game_over_):\n",
    "        # Two steps: first memorize the states, second learn from the pool\n",
    "        self.memory.remember([s_, n_s_, a_, r_, game_over_])\n",
    "        \n",
    "        input_states = np.zeros((self.batch_size, 5,5,self.n_state))\n",
    "        target_q = np.zeros((self.batch_size, 4))\n",
    "        if len(self.memory) >= self.batch_size:\n",
    "            for i in range(self.batch_size):\n",
    "                s, n_s, a, r, game_over = self.memory.random_access()\n",
    "\n",
    "                input_states[i] = s\n",
    "                \n",
    "                # Set target to prediction so that it only learns for selected action\n",
    "                target_q[i] = self.model.predict(np.expand_dims(s, axis=0), batch_size=1)[0]\n",
    "                \n",
    "                # Target for selected action = r + \\gamma * max_{a'} Q(ns, a')\n",
    "                target_q[i, a] = r\n",
    "\n",
    "                if not game_over:\n",
    "                    in_state = np.expand_dims(n_s, axis=0)\n",
    "                    max_value = self.model.predict(in_state, batch_size=1)\n",
    "                    max_value = max_value[0].max()\n",
    "                    target_q[i, a] += self.discount * max_value\n",
    "            ######## FILL IN\n",
    "            # HINT: Clip the target to avoid exploiding gradients.. -- clipping is a bit tighter\n",
    "            target_q = np.clip(target_q, -3, 3)\n",
    "\n",
    "            l = self.model.train_on_batch(input_states, target_q)\n",
    "\n",
    "            return l\n",
    "        \n",
    "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
    "        self.model.save_weights(name_weights, overwrite=True)\n",
    "        with open(name_model, \"w\") as outfile:\n",
    "            json.dump(self.model.to_json(), outfile)\n",
    "            \n",
    "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
    "        with open(name_model, \"r\") as jfile:\n",
    "            model = model_from_json(json.load(jfile))\n",
    "        model.load_weights(name_weights)\n",
    "        model.compile(\"sgd\", \"mse\")\n",
    "        self.model = model\n",
    "    \n",
    "class DQN_FC(DQN):\n",
    "    def __init__(self, *args, lr=0.1,**kwargs):\n",
    "        super(DQN_FC, self).__init__( *args,**kwargs)\n",
    "        \n",
    "        # NN Model\n",
    "        \n",
    "        model = Sequential([\n",
    "            Reshape((-1,), input_shape=(5, 5, self.n_state)),\n",
    "            Dense(64, activation=\"relu\"),\n",
    "            Dense(16, activation=\"relu\"),\n",
    "            Dense(4)\n",
    "        ])\n",
    "        \n",
    "        # model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
    "        model.compile(Adam(lr=lr, beta_1=0.9, beta_2=0.999), \"mse\")\n",
    "        self.model = model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000/051 | Loss 0.0035 | Win/lose count 1.0/0 (1.0)\n",
      "Epoch 001/051 | Loss 0.0010 | Win/lose count 2.0/2.0 (0.0)\n",
      "Epoch 002/051 | Loss 0.0064 | Win/lose count 2.0/1.0 (1.0)\n",
      "Epoch 003/051 | Loss 0.0039 | Win/lose count 3.5/1.0 (2.5)\n",
      "Epoch 004/051 | Loss 0.0020 | Win/lose count 0.5/0 (0.5)\n",
      "Epoch 005/051 | Loss 0.0650 | Win/lose count 3.0/1.0 (2.0)\n",
      "Epoch 006/051 | Loss 0.0537 | Win/lose count 1.0/5.0 (-4.0)\n",
      "Epoch 007/051 | Loss 0.0012 | Win/lose count 0.5/2.0 (-1.5)\n",
      "Epoch 008/051 | Loss 0.0032 | Win/lose count 1.5/1.0 (0.5)\n",
      "Epoch 009/051 | Loss 0.0015 | Win/lose count 1.0/1.0 (0.0)\n",
      "Epoch 010/051 | Loss 0.0058 | Win/lose count 1.5/1.0 (0.5)\n",
      "Epoch 011/051 | Loss 0.0020 | Win/lose count 1.5/2.0 (-0.5)\n",
      "Epoch 012/051 | Loss 0.0036 | Win/lose count 0.5/0 (0.5)\n",
      "Epoch 013/051 | Loss 0.0035 | Win/lose count 2.5/3.0 (-0.5)\n",
      "Epoch 014/051 | Loss 0.0013 | Win/lose count 4.0/0 (4.0)\n",
      "Epoch 015/051 | Loss 0.0037 | Win/lose count 2.5/2.0 (0.5)\n",
      "Epoch 016/051 | Loss 0.0017 | Win/lose count 2.5/2.0 (0.5)\n",
      "Epoch 017/051 | Loss 0.0034 | Win/lose count 1.0/2.0 (-1.0)\n",
      "Epoch 018/051 | Loss 0.0029 | Win/lose count 2.0/1.0 (1.0)\n",
      "Epoch 019/051 | Loss 0.0046 | Win/lose count 1.0/2.0 (-1.0)\n",
      "Epoch 020/051 | Loss 0.0075 | Win/lose count 3.0/1.0 (2.0)\n",
      "Epoch 021/051 | Loss 0.0020 | Win/lose count 3.0/0 (3.0)\n",
      "Epoch 022/051 | Loss 0.0061 | Win/lose count 1.5/1.0 (0.5)\n",
      "Epoch 023/051 | Loss 0.0396 | Win/lose count 4.5/0 (4.5)\n",
      "Epoch 024/051 | Loss 0.0222 | Win/lose count 1.5/0 (1.5)\n",
      "Epoch 025/051 | Loss 0.0016 | Win/lose count 1.5/0 (1.5)\n",
      "Epoch 026/051 | Loss 0.0622 | Win/lose count 1.5/0 (1.5)\n",
      "Epoch 027/051 | Loss 0.0017 | Win/lose count 3.5/1.0 (2.5)\n",
      "Epoch 028/051 | Loss 0.0022 | Win/lose count 4.0/1.0 (3.0)\n",
      "Epoch 029/051 | Loss 0.0020 | Win/lose count 2.0/0 (2.0)\n",
      "Epoch 030/051 | Loss 0.0040 | Win/lose count 2.5/0 (2.5)\n",
      "Epoch 031/051 | Loss 0.0025 | Win/lose count 1.0/2.0 (-1.0)\n",
      "Epoch 032/051 | Loss 0.0297 | Win/lose count 3.5/2.0 (1.5)\n",
      "Epoch 033/051 | Loss 0.0024 | Win/lose count 2.0/0 (2.0)\n",
      "Epoch 034/051 | Loss 0.0018 | Win/lose count 4.0/0 (4.0)\n",
      "Epoch 035/051 | Loss 0.0544 | Win/lose count 2.5/1.0 (1.5)\n",
      "Epoch 036/051 | Loss 0.0013 | Win/lose count 3.0/2.0 (1.0)\n",
      "Epoch 037/051 | Loss 0.0036 | Win/lose count 1.0/1.0 (0.0)\n",
      "Epoch 038/051 | Loss 0.0033 | Win/lose count 3.0/1.0 (2.0)\n",
      "Epoch 039/051 | Loss 0.0010 | Win/lose count 3.0/1.0 (2.0)\n",
      "Epoch 040/051 | Loss 0.0027 | Win/lose count 3.0/0 (3.0)\n",
      "Epoch 041/051 | Loss 0.0026 | Win/lose count 1.0/0 (1.0)\n",
      "Epoch 042/051 | Loss 0.0010 | Win/lose count 4.5/1.0 (3.5)\n",
      "Epoch 043/051 | Loss 0.0010 | Win/lose count 5.0/0 (5.0)\n",
      "Epoch 044/051 | Loss 0.0057 | Win/lose count 1.5/3.0 (-1.5)\n",
      "Epoch 045/051 | Loss 0.0012 | Win/lose count 1.0/0 (1.0)\n",
      "Epoch 046/051 | Loss 0.0011 | Win/lose count 4.5/1.0 (3.5)\n",
      "Epoch 047/051 | Loss 0.0018 | Win/lose count 2.0/1.0 (1.0)\n",
      "Epoch 048/051 | Loss 0.0037 | Win/lose count 2.0/0 (2.0)\n",
      "Epoch 049/051 | Loss 0.0030 | Win/lose count 1.5/1.0 (0.5)\n",
      "Epoch 050/051 | Loss 0.0033 | Win/lose count 2.5/1.0 (1.5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent = DQN_FC(size, lr=.001, epsilon = 0.2, memory_size=2000, batch_size = 32)\n",
    "train(agent, env, 51, prefix='fc_train')\n",
    "HTML(display_videos('fc_train10.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment(grid_size=size, max_time=T, temperature=0.05)\n",
    "agent = DQN_FC(size, lr=.001, epsilon = 0.2, memory_size=2000, batch_size = 32)\n",
    "train(agent, env, 51, prefix='fc_train_low_temp')\n",
    "HTML(display_videos('fc_train_low_temp10.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***\n",
    "***\n",
    "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN_CNN(DQN):\n",
    "    def __init__(self, *args,lr=0.1,**kwargs):\n",
    "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
    "        \n",
    "        model = Sequential([\n",
    "            Conv2D(64, (2, 2), input_shape=(5, 5, self.n_state), \n",
    "                   data_format=\"channels_last\", activation=\"relu\"),\n",
    "            Conv2D(32, (2, 2), activation=\"relu\"),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "            Reshape((-1,)),\n",
    "            Dense(4)\n",
    "        ])\n",
    "        \n",
    "        model.compile(Adam(lr=lr, beta_1=0.9, beta_2=0.999), \"mse\")\n",
    "        self.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000/051 | Loss 0.0024 | Win/lose count 10.0/10.0 (0.0)\n",
      "Epoch 001/051 | Loss 0.0643 | Win/lose count 11.5/15.0 (-3.5)\n",
      "Epoch 002/051 | Loss 0.0491 | Win/lose count 16.0/13.0 (3.0)\n",
      "Epoch 003/051 | Loss 0.0028 | Win/lose count 8.5/8.0 (0.5)\n",
      "Epoch 004/051 | Loss 0.0670 | Win/lose count 7.0/10.0 (-3.0)\n",
      "Epoch 005/051 | Loss 0.0058 | Win/lose count 11.5/8.0 (3.5)\n",
      "Epoch 006/051 | Loss 0.0048 | Win/lose count 13.0/10.0 (3.0)\n",
      "Epoch 007/051 | Loss 0.0060 | Win/lose count 13.5/10.0 (3.5)\n",
      "Epoch 008/051 | Loss 0.0042 | Win/lose count 11.0/7.0 (4.0)\n",
      "Epoch 009/051 | Loss 0.0014 | Win/lose count 10.0/7.0 (3.0)\n",
      "Epoch 010/051 | Loss 0.0038 | Win/lose count 7.5/14.0 (-6.5)\n",
      "Epoch 011/051 | Loss 0.0060 | Win/lose count 8.0/7.0 (1.0)\n",
      "Epoch 012/051 | Loss 0.0839 | Win/lose count 9.5/5.0 (4.5)\n",
      "Epoch 013/051 | Loss 0.0053 | Win/lose count 6.5/5.0 (1.5)\n",
      "Epoch 014/051 | Loss 0.0053 | Win/lose count 11.0/10.0 (1.0)\n",
      "Epoch 015/051 | Loss 0.0039 | Win/lose count 8.0/8.0 (0.0)\n",
      "Epoch 016/051 | Loss 0.0013 | Win/lose count 7.5/9.0 (-1.5)\n",
      "Epoch 017/051 | Loss 0.0017 | Win/lose count 16.0/13.0 (3.0)\n",
      "Epoch 018/051 | Loss 0.0017 | Win/lose count 5.5/10.0 (-4.5)\n",
      "Epoch 019/051 | Loss 0.0043 | Win/lose count 10.5/12.0 (-1.5)\n",
      "Epoch 020/051 | Loss 0.0043 | Win/lose count 11.5/10.0 (1.5)\n",
      "Epoch 021/051 | Loss 0.0049 | Win/lose count 8.0/8.0 (0.0)\n",
      "Epoch 022/051 | Loss 0.0036 | Win/lose count 7.0/5.0 (2.0)\n",
      "Epoch 023/051 | Loss 0.0030 | Win/lose count 10.5/12.0 (-1.5)\n",
      "Epoch 024/051 | Loss 0.0045 | Win/lose count 10.5/8.0 (2.5)\n",
      "Epoch 025/051 | Loss 0.0021 | Win/lose count 7.5/11.0 (-3.5)\n",
      "Epoch 026/051 | Loss 0.0035 | Win/lose count 11.5/11.0 (0.5)\n",
      "Epoch 027/051 | Loss 0.0024 | Win/lose count 7.0/6.0 (1.0)\n",
      "Epoch 028/051 | Loss 0.0032 | Win/lose count 11.5/8.0 (3.5)\n",
      "Epoch 029/051 | Loss 0.0036 | Win/lose count 14.5/12.0 (2.5)\n",
      "Epoch 030/051 | Loss 0.0012 | Win/lose count 6.0/7.0 (-1.0)\n",
      "Epoch 031/051 | Loss 0.0036 | Win/lose count 10.5/10.0 (0.5)\n",
      "Epoch 032/051 | Loss 0.0034 | Win/lose count 9.0/9.0 (0.0)\n",
      "Epoch 033/051 | Loss 0.0025 | Win/lose count 9.0/7.0 (2.0)\n",
      "Epoch 034/051 | Loss 0.0034 | Win/lose count 8.5/11.0 (-2.5)\n",
      "Epoch 035/051 | Loss 0.0058 | Win/lose count 11.0/8.0 (3.0)\n",
      "Epoch 036/051 | Loss 0.0019 | Win/lose count 4.0/7.0 (-3.0)\n",
      "Epoch 037/051 | Loss 0.0013 | Win/lose count 9.0/8.0 (1.0)\n",
      "Epoch 038/051 | Loss 0.0025 | Win/lose count 11.0/6.0 (5.0)\n",
      "Epoch 039/051 | Loss 0.0036 | Win/lose count 7.5/11.0 (-3.5)\n",
      "Epoch 040/051 | Loss 0.0100 | Win/lose count 15.0/10.0 (5.0)\n",
      "Epoch 041/051 | Loss 0.0031 | Win/lose count 12.5/12.0 (0.5)\n",
      "Epoch 042/051 | Loss 0.0024 | Win/lose count 8.0/10.0 (-2.0)\n",
      "Epoch 043/051 | Loss 0.0555 | Win/lose count 8.0/13.0 (-5.0)\n",
      "Epoch 044/051 | Loss 0.0103 | Win/lose count 8.0/8.0 (0.0)\n",
      "Epoch 045/051 | Loss 0.0038 | Win/lose count 6.5/9.0 (-2.5)\n",
      "Epoch 046/051 | Loss 0.0026 | Win/lose count 10.5/13.0 (-2.5)\n",
      "Epoch 047/051 | Loss 0.0015 | Win/lose count 12.5/9.0 (3.5)\n",
      "Epoch 048/051 | Loss 0.0403 | Win/lose count 13.0/13.0 (0.0)\n",
      "Epoch 049/051 | Loss 0.0039 | Win/lose count 12.0/14.0 (-2.0)\n",
      "Epoch 050/051 | Loss 0.0010 | Win/lose count 7.0/5.0 (2.0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent = DQN_CNN(size, lr=.001, epsilon = 0.6, memory_size=2000, batch_size=32)\n",
    "train(agent,env,51,prefix='cnn_train')\n",
    "HTML(display_videos('cnn_train50.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test of the CNN\n",
      "Win/lose count 0/0. Average score (0.0)\n",
      "Win/lose count 0/0. Average score (0.0)\n",
      "Win/lose count 0/0. Average score (0.0)\n",
      "Win/lose count 0/0. Average score (0.0)\n",
      "Win/lose count 0/0. Average score (0.0)\n",
      "Win/lose count 0.5/0. Average score (0.08333333333333333)\n",
      "Win/lose count 0/0. Average score (0.07142857142857142)\n",
      "Win/lose count 0/0. Average score (0.0625)\n",
      "Win/lose count 0.5/0. Average score (0.1111111111111111)\n",
      "Win/lose count 0/0. Average score (0.1)\n",
      "Win/lose count 0.5/0. Average score (0.13636363636363635)\n",
      "Final score: 0.13636363636363635\n",
      "Test of the FC\n",
      "Win/lose count 0/0. Average score (0.0)\n",
      "Win/lose count 0/0. Average score (0.0)\n",
      "Win/lose count 0/0. Average score (0.0)\n",
      "Win/lose count 0.5/0. Average score (0.125)\n",
      "Win/lose count 0/0. Average score (0.1)\n",
      "Win/lose count 0/0. Average score (0.08333333333333333)\n",
      "Win/lose count 0/0. Average score (0.07142857142857142)\n",
      "Win/lose count 0.5/0. Average score (0.125)\n",
      "Win/lose count 0/0. Average score (0.1111111111111111)\n",
      "Win/lose count 0/0. Average score (0.1)\n",
      "Win/lose count 1.0/0. Average score (0.18181818181818182)\n",
      "Final score: 0.18181818181818182\n"
     ]
    }
   ],
   "source": [
    "env = Environment(grid_size=size, max_time=T,temperature=0.01)\n",
    "agent_cnn_lt = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "agent_cnn_lt.load(name_weights='cnn_train_low_tempmodel.h5',name_model='cnn_train_low_tempmodel.json')\n",
    "\n",
    "agent_fc_lt = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "agent_fc_lt.load(name_weights='fc_train_low_tempmodel.h5',name_model='fc_train_low_tempmodel.json')\n",
    "print('Test of the CNN')\n",
    "test(agent_cnn_lt,env,epochs_test,prefix='cnn_test')\n",
    "print('Test of the FC')\n",
    "test(agent_fc_lt,env,epochs_test,prefix='fc_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test of the CNN\n",
      "Win/lose count 1.5/0. Average score (1.5)\n",
      "Win/lose count 0.5/0. Average score (1.0)\n",
      "Win/lose count 1.0/0. Average score (1.0)\n",
      "Win/lose count 1.0/0. Average score (1.0)\n",
      "Win/lose count 0.5/1.0. Average score (0.7)\n",
      "Win/lose count 1.0/0. Average score (0.75)\n",
      "Win/lose count 1.5/0. Average score (0.8571428571428571)\n",
      "Win/lose count 2.5/0. Average score (1.0625)\n",
      "Win/lose count 2.5/0. Average score (1.2222222222222223)\n",
      "Win/lose count 1.5/1.0. Average score (1.15)\n",
      "Win/lose count 0.5/0. Average score (1.0909090909090908)\n",
      "Final score: 1.0909090909090908\n",
      "Test of the FC\n",
      "Win/lose count 2.0/0. Average score (2.0)\n",
      "Win/lose count 1.5/0. Average score (1.75)\n",
      "Win/lose count 1.0/0. Average score (1.5)\n",
      "Win/lose count 1.0/0. Average score (1.375)\n",
      "Win/lose count 1.0/0. Average score (1.3)\n",
      "Win/lose count 2.0/0. Average score (1.4166666666666667)\n",
      "Win/lose count 0.5/0. Average score (1.2857142857142858)\n",
      "Win/lose count 3.5/0. Average score (1.5625)\n",
      "Win/lose count 2.5/0. Average score (1.6666666666666667)\n",
      "Win/lose count 2.5/0. Average score (1.75)\n",
      "Win/lose count 1.5/0. Average score (1.7272727272727273)\n",
      "Final score: 1.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "env = Environment(grid_size=size, max_time=T,temperature=0.3)\n",
    "agent_cnn = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "agent_cnn.load(name_weights='cnn_trainmodel.h5',name_model='cnn_trainmodel.json')\n",
    "\n",
    "agent_fc = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "agent_fc.load(name_weights='fc_trainmodel.h5',name_model='fc_trainmodel.json')\n",
    "print('Test of the CNN')\n",
    "test(agent_cnn,env,epochs_test,prefix='cnn_test')\n",
    "print('Test of the FC')\n",
    "test(agent_fc,env,epochs_test,prefix='fc_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(display_videos('cnn_test2.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAFaNtZGF0AAACrQYF//+p3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1NSByMjkxNyAwYTg0ZDk4IC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAxOCAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MToweDExMSBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MCBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD00IHRocmVhZHM9OCBsb29rYWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFjZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJhbWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdlaWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MjUgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVzaD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBxcG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAALtZYiEADf//vaH+BTZWBP+Wb/9DX/cj9uPrP1xYyEE31qvIejAGS+1H+b/rFFs6Z6UB/fgCJQAc24ZwpJw4v/ApLdW+BTLYTkVLnX1aIxw4jw34T+sr5nf6CxMUuUUswAfRqgEhC3MhJ24yCWp75VJBe9oedgOImH+JqTMFfP3ECX3PreHJzzW4mv0slmGWLrXtUTohMwYZT8fkIEMAMidX1ZS42FSW5nC+uMEUJ+binQv+ZKBRZFliwY/WkjApVMgtWm4qwVCsUL66EtcYl7f0e9ACiCbJbSJZySmngvc4Zgw1edC4kPA+pJGqIdC5QAFtIIWEZztrD7gC2mAryAvcZNebk5gDVooDmCuP9Pc9LYIRHhCWOB9GGzEE7P6yvuG7Ql7Vk+dJXKrZTqcs90kF3yLXiH8CkBgYQGAsMR8gH4LbRRiHExHY/6odZSjPHidagesLJTVIeCmoIR2SUewA5MyXglNzdHOtHdf/rE48j968DdOhY6AFzhhxSkwk15ibsq+MDIG4VkxHdCLFI2PCGtMalR0Fd5uN93V2uMBUtRKC15xhZz0QmViuf/oSRc2sako65MpZcpL3iznEjCkblVuB8QA1/keWfSQr0oLYffkRo8Csm2oYtiB5LtqIhnxuHVdERyJW6mzwSsCqrIj/yTXA8Z0Gaf8jwW6Y/PDBD7nUuudEOl8Dn3BMByXW7/1iN7FQgPM/YwnsGLASdaA44KFZCw0LgDeORzWOfiCGbC50G+NqvN4qsA1em6uR5Ryx1DC9RX61lWgxYFYHu+nUBqKlCLjBYPoAhocFlJcErYUBo92BJwANbpLZWqvuaPV2uKKrSEi6ZQ/HPx38l8wIPpCIPX0FKAoylMASK7funHjx1H7f7aF5ArtCJR/wEYl1oLxdJrickcBid4d9nrIASswvLk3fr3yP+kToO1jIbnTCqb4iThJoRD6I1VTwpEV+DsHdxDDtM03r4vAVOsbrWMAQAXx91kXLWUABOUAAAAWQZojbEM//p4QANj6+/VCOrtEfVFjgAAAAA9BnkF4hX8ALXaO8034uY8AAAAOAZ5iakK/AC1tjHoiuY4AAAAZQZpkSahBaJlMCGf//p4QAId8Q863QMkRnQAAABhBmoVJ4QpSZTAhn/6eEADNyGOfw5zfWoEAAAAdQZqnSeEOiZTBTRMM//6eEADO+/v0wKMkq3WV5MEAAAAPAZ7GakK/ACstZTNsyNf/AAAAGEGayEnhDyZTAhn//p4QAMT6+/kSI+sKLgAAABhBmulJ4Q8mUwIZ//6eEAB8vX38iRH1hbMAAAAYQZsKSeEPJlMCGf/+nhAAU+vcaF033XJNAAAAGEGbK0nhDyZTAhv//qeEABYcVpBCJ/lumwAAABtBm05J4Q8mUwIZ//6eEABY/dN7gB1cYx9UikAAAAARQZ9sRRE8K/8AElzRvNN71YUAAAAPAZ+NakK/ABJZW6UaQ8aXAAAAGUGbj0moQWiZTAhn//6eEAA3fr7+RIj6w+kAAAAYQZuwSeEKUmUwIb/+p4QACWj5jyMT/LgNAAAAG0Gb0UnhDomUwIb//qeEAAmo+Y8jKIE7/o3rgAAAABhBm/JJ4Q8mUwId//6plgAE4KOdKlu5R8EAAAASQZoWSeEPJlMCHf/+qZYAAJWAAAAADEGeNEURPC//AACygAAAABABnlN0Qr8AB4VDd07Ls2CBAAAADwGeVWpCvwAHhUN2GerQiQAAABNBmlpJqEFomUwId//+qZYAAJWBAAAADEGeeEURLC//AACygQAAABABnpd0Qr8AB4VDd07Ls2CAAAAADwGemWpCvwAHhUN2GerQiQAAABNBmp5JqEFsmUwId//+qZYAAJWAAAAADEGevEUVLC//AACygQAAABABntt0Qr8AB4VDd07Ls2CBAAAADwGe3WpCvwAHhUN2GerQiQAAABNBmsJJqEFsmUwId//+qZYAAJWAAAAADEGe4EUVLC//AACygQAAABABnx90Qr8AB4VDd07Ls2CAAAAADwGfAWpCvwAHhUN2GerQiQAAABNBmwZJqEFsmUwId//+qZYAAJWAAAAADEGfJEUVLC//AACygQAAABABn0N0Qr8AB4VDd07Ls2CBAAAADwGfRWpCvwAHhUN2GerQiQAAABNBm0pJqEFsmUwId//+qZYAAJWBAAAADEGfaEUVLC//AACygAAAABABn4d0Qr8AB4VDd07Ls2CAAAAADwGfiWpCvwAHhUN2GerQiQAAABNBm45JqEFsmUwId//+qZYAAJWAAAAADEGfrEUVLC//AACygAAAABABn8t0Qr8AB4VDd07Ls2CBAAAADwGfzWpCvwAHhUN2GerQiQAAABNBm9JJqEFsmUwId//+qZYAAJWBAAAADEGf8EUVLC//AACygAAAABABng90Qr8AB4VDd07Ls2CAAAAADwGeEWpCvwAHhUN2GerQiQAAABNBmhZJqEFsmUwId//+qZYAAJWAAAAADEGeNEUVLC//AACygAAAABABnlN0Qr8AB4VDd07Ls2CBAAAADwGeVWpCvwAHhUN2GerQiQAAABNBmlpJqEFsmUwId//+qZYAAJWBAAAADEGeeEUVLC//AACygQAAABABnpd0Qr8AB4VDd07Ls2CAAAAADwGemWpCvwAHhUN2GerQiQAAABNBmp5JqEFsmUwId//+qZYAAJWAAAAADEGevEUVLC//AACygQAAABABntt0Qr8AB4VDd07Ls2CBAAAADwGe3WpCvwAHhUN2GerQiQAAABNBmsJJqEFsmUwId//+qZYAAJWAAAAADEGe4EUVLC//AACygQAAABABnx90Qr8AB4VDd07Ls2CAAAAADwGfAWpCvwAHhUN2GerQiQAAABNBmwZJqEFsmUwId//+qZYAAJWAAAAADEGfJEUVLC//AACygQAAABABn0N0Qr8AB4VDd07Ls2CBAAAADwGfRWpCvwAHhUN2GerQiQAAABNBm0pJqEFsmUwId//+qZYAAJWBAAAADEGfaEUVLC//AACygAAAABABn4d0Qr8AB4VDd07Ls2CAAAAADwGfiWpCvwAHhUN2GerQiQAAABNBm45JqEFsmUwId//+qZYAAJWAAAAADEGfrEUVLC//AACygAAAABABn8t0Qr8AB4VDd07Ls2CBAAAADwGfzWpCvwAHhUN2GerQiQAAABNBm9JJqEFsmUwId//+qZYAAJWBAAAADEGf8EUVLC//AACygAAAABABng90Qr8AB4VDd07Ls2CAAAAADwGeEWpCvwAHhUN2GerQiQAAABNBmhZJqEFsmUwId//+qZYAAJWAAAAADEGeNEUVLC//AACygAAAABABnlN0Qr8AB4VDd07Ls2CBAAAADwGeVWpCvwAHhUN2GerQiQAAABNBmlpJqEFsmUwId//+qZYAAJWBAAAADEGeeEUVLC//AACygQAAABABnpd0Qr8AB4VDd07Ls2CAAAAADwGemWpCvwAHhUN2GerQiQAAABNBmp5JqEFsmUwId//+qZYAAJWAAAAADEGevEUVLC//AACygQAAABABntt0Qr8AB4VDd07Ls2CBAAAADwGe3WpCvwAHhUN2GerQiQAAABNBmsJJqEFsmUwId//+qZYAAJWAAAAADEGe4EUVLC//AACygQAAABABnx90Qr8AB4VDd07Ls2CAAAAADwGfAWpCvwAHhUN2GerQiQAAABNBmwZJqEFsmUwId//+qZYAAJWAAAAADEGfJEUVLC//AACygQAAABABn0N0Qr8AB4VDd07Ls2CBAAAADwGfRWpCvwAHhUN2GerQiQAAABNBm0pJqEFsmUwId//+qZYAAJWBAAAADEGfaEUVLC//AACygAAAABABn4d0Qr8AB4VDd07Ls2CAAAAADwGfiWpCvwAHhUN2GerQiQAAABNBm45JqEFsmUwId//+qZYAAJWAAAAADEGfrEUVLC//AACygAAAABABn8t0Qr8AB4VDd07Ls2CBAAAADwGfzWpCvwAHhUN2GerQiQAAABNBm9JJqEFsmUwId//+qZYAAJWBAAAADEGf8EUVLC//AACygAAAABABng90Qr8AB4VDd07Ls2CAAAAADwGeEWpCvwAHhUN2GerQiQAAABNBmhZJqEFsmUwId//+qZYAAJWAAAAADEGeNEUVLC//AACygAAAABABnlN0Qr8AB4VDd07Ls2CBAAAADwGeVWpCvwAHhUN2GerQiQAAABNBmlpJqEFsmUwId//+qZYAAJWBAAAADEGeeEUVLC//AACygQAAABABnpd0Qr8AB4VDd07Ls2CAAAAADwGemWpCvwAHhUN2GerQiQAAABNBmp5JqEFsmUwId//+qZYAAJWAAAAADEGevEUVLC//AACygQAAABABntt0Qr8AB4VDd07Ls2CBAAAADwGe3WpCvwAHhUN2GerQiQAAABNBmsJJqEFsmUwId//+qZYAAJWAAAAADEGe4EUVLC//AACygQAAABABnx90Qr8AB4VDd07Ls2CAAAAADwGfAWpCvwAHhUN2GerQiQAAABNBmwZJqEFsmUwId//+qZYAAJWAAAAADEGfJEUVLC//AACygQAAABABn0N0Qr8AB4VDd07Ls2CBAAAADwGfRWpCvwAHhUN2GerQiQAAABNBm0pJqEFsmUwId//+qZYAAJWBAAAADEGfaEUVLC//AACygAAAABABn4d0Qr8AB4VDd07Ls2CAAAAADwGfiWpCvwAHhUN2GerQiQAAABNBm45JqEFsmUwId//+qZYAAJWAAAAADEGfrEUVLC//AACygAAAABABn8t0Qr8AB4VDd07Ls2CBAAAADwGfzWpCvwAHhUN2GerQiQAAABNBm9JJqEFsmUwId//+qZYAAJWBAAAADEGf8EUVLC//AACygAAAABABng90Qr8AB4VDd07Ls2CAAAAADwGeEWpCvwAHhUN2GerQiQAAABNBmhZJqEFsmUwId//+qZYAAJWAAAAADEGeNEUVLC//AACygAAAABABnlN0Qr8AB4VDd07Ls2CBAAAADwGeVWpCvwAHhUN2GerQiQAAABNBmlpJqEFsmUwId//+qZYAAJWBAAAADEGeeEUVLC//AACygQAAABABnpd0Qr8AB4VDd07Ls2CAAAAADwGemWpCvwAHhUN2GerQiQAAABNBmp5JqEFsmUwId//+qZYAAJWAAAAADEGevEUVLC//AACygQAAABABntt0Qr8AB4VDd07Ls2CBAAAADwGe3WpCvwAHhUN2GerQiQAAABNBmsJJqEFsmUwId//+qZYAAJWAAAAADEGe4EUVLC//AACygQAAABABnx90Qr8AB4VDd07Ls2CAAAAADwGfAWpCvwAHhUN2GerQiQAAABNBmwZJqEFsmUwId//+qZYAAJWAAAAADEGfJEUVLC//AACygQAAABABn0N0Qr8AB4VDd07Ls2CBAAAADwGfRWpCvwAHhUN2GerQiQAAABNBm0pJqEFsmUwId//+qZYAAJWBAAAADEGfaEUVLC//AACygAAAABABn4d0Qr8AB4VDd07Ls2CAAAAADwGfiWpCvwAHhUN2GerQiQAAABNBm45JqEFsmUwId//+qZYAAJWAAAAADEGfrEUVLC//AACygAAAABABn8t0Qr8AB4VDd07Ls2CBAAAADwGfzWpCvwAHhUN2GerQiQAAABNBm9JJqEFsmUwId//+qZYAAJWBAAAADEGf8EUVLC//AACygAAAABABng90Qr8AB4VDd07Ls2CAAAAADwGeEWpCvwAHhUN2GerQiQAAABNBmhZJqEFsmUwId//+qZYAAJWAAAAADEGeNEUVLC//AACygAAAABABnlN0Qr8AB4VDd07Ls2CBAAAADwGeVWpCvwAHhUN2GerQiQAAABNBmlpJqEFsmUwId//+qZYAAJWBAAAADEGeeEUVLC//AACygQAAABABnpd0Qr8AB4VDd07Ls2CAAAAADwGemWpCvwAHhUN2GerQiQAAABNBmp5JqEFsmUwId//+qZYAAJWAAAAADEGevEUVLC//AACygQAAABABntt0Qr8AB4VDd07Ls2CBAAAADwGe3WpCvwAHhUN2GerQiQAAABJBmsJJqEFsmUwIb//+p4QAAScAAAAMQZ7gRRUsL/8AALKBAAAAEAGfH3RCvwAHhUN3TsuzYIAAAAAPAZ8BakK/AAeFQ3YZ6tCJAAAAEkGbBkmoQWyZTAhn//6eEAAEfAAAAAxBnyRFFSwv/wAAsoEAAAAQAZ9DdEK/AAeFQ3dOy7NggQAAAA8Bn0VqQr8AB4VDdhnq0IkAAAAaQZtJS6hCEFskRggoB/IB/YeAIV/+OEAAEXEAAAAnQZ9nRRUsK/8Cr2PtQcTdqsNJJuWqhgcstbvNKiCaH5CNxfTnqJbAAAAAIgGfiGpCvwKvY+1BxN2qw0km5aqGByy1u80qIJohHbh5lxgAAAw4bW9vdgAAAGxtdmhkAAAAAAAAAAAAAAAAAAAD6AAAH5AAAQAAAQAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgAAC2J0cmFrAAAAXHRraGQAAAADAAAAAAAAAAAAAAABAAAAAAAAH5AAAAAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAARAAAAEQAAAAAAAkZWR0cwAAABxlbHN0AAAAAAAAAAEAAB+QAAAEAAABAAAAAArabWRpYQAAACBtZGhkAAAAAAAAAAAAAAAAAAAyAAABlABVxAAAAAAALWhkbHIAAAAAAAAAAHZpZGUAAAAAAAAAAAAAAABWaWRlb0hhbmRsZXIAAAAKhW1pbmYAAAAUdm1oZAAAAAEAAAAAAAAAAAAAACRkaW5mAAAAHGRyZWYAAAAAAAAAAQAAAAx1cmwgAAAAAQAACkVzdGJsAAAAlXN0c2QAAAAAAAAAAQAAAIVhdmMxAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAARABEABIAAAASAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGP//AAAAL2F2Y0MB9AAN/+EAF2f0AA2RmygiEdCAAAADAIAAABkHihTLAQAFaOvjxEgAAAAYc3R0cwAAAAAAAAABAAAAygAAAgAAAAAUc3RzcwAAAAAAAAABAAAAAQAABhBjdHRzAAAAAAAAAMAAAAABAAAEAAAAAAEAAAgAAAAAAgAAAgAAAAACAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAAEAAAEAAAAAAEAAAgAAAAAAgAAAgAAAAAEAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAgAAAAAAgAAAgAAAAAcc3RzYwAAAAAAAAABAAAAAQAAAMoAAAABAAADPHN0c3oAAAAAAAAAAAAAAMoAAAWiAAAAGgAAABMAAAASAAAAHQAAABwAAAAhAAAAEwAAABwAAAAcAAAAHAAAABwAAAAfAAAAFQAAABMAAAAdAAAAHAAAAB8AAAAcAAAAFgAAABAAAAAUAAAAEwAAABcAAAAQAAAAFAAAABMAAAAXAAAAEAAAABQAAAATAAAAFwAAABAAAAAUAAAAEwAAABcAAAAQAAAAFAAAABMAAAAXAAAAEAAAABQAAAATAAAAFwAAABAAAAAUAAAAEwAAABcAAAAQAAAAFAAAABMAAAAXAAAAEAAAABQAAAATAAAAFwAAABAAAAAUAAAAEwAAABcAAAAQAAAAFAAAABMAAAAXAAAAEAAAABQAAAATAAAAFwAAABAAAAAUAAAAEwAAABcAAAAQAAAAFAAAABMAAAAXAAAAEAAAABQAAAATAAAAFwAAABAAAAAUAAAAEwAAABcAAAAQAAAAFAAAABMAAAAXAAAAEAAAABQAAAATAAAAFwAAABAAAAAUAAAAEwAAABcAAAAQAAAAFAAAABMAAAAXAAAAEAAAABQAAAATAAAAFwAAABAAAAAUAAAAEwAAABcAAAAQAAAAFAAAABMAAAAXAAAAEAAAABQAAAATAAAAFwAAABAAAAAUAAAAEwAAABcAAAAQAAAAFAAAABMAAAAXAAAAEAAAABQAAAATAAAAFwAAABAAAAAUAAAAEwAAABcAAAAQAAAAFAAAABMAAAAXAAAAEAAAABQAAAATAAAAFwAAABAAAAAUAAAAEwAAABcAAAAQAAAAFAAAABMAAAAXAAAAEAAAABQAAAATAAAAFwAAABAAAAAUAAAAEwAAABcAAAAQAAAAFAAAABMAAAAXAAAAEAAAABQAAAATAAAAFwAAABAAAAAUAAAAEwAAABcAAAAQAAAAFAAAABMAAAAXAAAAEAAAABQAAAATAAAAFwAAABAAAAAUAAAAEwAAABcAAAAQAAAAFAAAABMAAAAXAAAAEAAAABQAAAATAAAAFwAAABAAAAAUAAAAEwAAABYAAAAQAAAAFAAAABMAAAAWAAAAEAAAABQAAAATAAAAHgAAACsAAAAmAAAAFHN0Y28AAAAAAAAAAQAAADAAAABidWR0YQAAAFptZXRhAAAAAAAAACFoZGxyAAAAAAAAAABtZGlyYXBwbAAAAAAAAAAAAAAAAC1pbHN0AAAAJal0b28AAAAdZGF0YQAAAAEAAAAATGF2ZjU4LjIwLjEwMA==\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(display_videos('fc_test0.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We observe that when the proportion of food is important, the rat only gets the food next to him and is avoiding the poison, then go into a useless pattern (like looping between right and left).\n",
    ">\n",
    "> If we decrease the temperature, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
    "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
    "2. Append via the environment a new state that describes if a cell has been visited or not\n",
    "\n",
    "***\n",
    "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_explore(agent,env,epoch, epsilon_start=0.7, epsilon_end=0.1, epsilon_decay=60000, prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "    loss = 0\n",
    "    steps_done = 0\n",
    "    \n",
    "    agent.set_epsilon(epsilon_start)\n",
    "    \n",
    "    for e in range(epoch):\n",
    "       \n",
    "        \n",
    "        # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will terminate\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "\n",
    "        while not game_over:\n",
    "            # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action, train=True)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "\n",
    "            # Apply the reinforcement strategy\n",
    "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "            \n",
    "            eps_threshold = epsilon_start + (epsilon_end - epsilon_start) * steps_done / epsilon_decay\n",
    "        \n",
    "            agent.set_epsilon(eps_threshold)\n",
    "            steps_done += 1\n",
    "\n",
    "        # Save as a mp4\n",
    "        if e % 10 == 0:\n",
    "            env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score += win-lose\n",
    "\n",
    "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "              .format(e, epoch, loss, win, lose, win-lose))\n",
    "        agent.save(name_weights=\"models/\" + prefix+'model.h5',name_model=\"models/\" + prefix+'model.json')\n",
    "        \n",
    "class EnvironmentExploring(Environment):\n",
    "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
    "        super(EnvironmentExploring, self).__init__(grid_size, max_time, temperature)\n",
    "        \n",
    "        self.malus_position = np.zeros_like(self.position)\n",
    "    \n",
    "    def act(self, action, train=False):\n",
    "        \"\"\"This function returns the new state, reward and decides if the\n",
    "        game ends.\"\"\"\n",
    "\n",
    "        self.get_frame(int(self.t))\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "\n",
    "        self.position[self.x, self.y] = 1\n",
    "        \n",
    "        # WHAT CHANGED\n",
    "        # we add explored cases here\n",
    "        self.malus_position[self.x, self.y] += 0.1\n",
    "        ##########\n",
    "        \n",
    "        if action == 0:  # Right\n",
    "            if self.x == self.grid_size-3:\n",
    "                self.x = self.x-1\n",
    "            else:\n",
    "                self.x = self.x + 1\n",
    "        elif action == 1:  # Left\n",
    "            if self.x == 2:\n",
    "                self.x = self.x+1\n",
    "            else:\n",
    "                self.x = self.x-1\n",
    "        elif action == 2:  # Up\n",
    "            if self.y == self.grid_size - 3:\n",
    "                self.y = self.y - 1\n",
    "            else:\n",
    "                self.y = self.y + 1\n",
    "        elif action == 3:  # Down\n",
    "            if self.y == 2:\n",
    "                self.y = self.y + 1\n",
    "            else:\n",
    "                self.y = self.y - 1\n",
    "        else:\n",
    "            RuntimeError('Error: action not recognized')\n",
    "            \n",
    "\n",
    "        self.t = self.t + 1\n",
    "        reward = self.board[self.x, self.y]\n",
    "        if train:\n",
    "            reward -= self.malus_position[self.x, self.y]\n",
    "        self.board[self.x, self.y] = 0\n",
    "        game_over = self.t > self.max_time\n",
    "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                                self.position.reshape(self.grid_size, self.grid_size,1),\n",
    "                                self.malus_position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
    "\n",
    "        return state, reward, game_over\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
    "\n",
    "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "\n",
    "\n",
    "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
    "\n",
    "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
    "\n",
    "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "        malus[bonus>0]=0\n",
    "\n",
    "        self.board = bonus + malus\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.malus_position = np.zeros_like(self.position)\n",
    "        \n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.board[self.x,self.y] = 0\n",
    "        self.t = 0\n",
    "\n",
    "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                                self.position.reshape(self.grid_size, self.grid_size,1),\n",
    "                                self.malus_position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "\n",
    "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
    "        return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000/051 | Loss 0.0211 | Win/lose count 10.5/49.60000000000005 (-39.10000000000005)\n",
      "Epoch 001/051 | Loss 0.0060 | Win/lose count 18.0/34.00000000000001 (-16.000000000000007)\n",
      "Epoch 002/051 | Loss 0.0129 | Win/lose count 11.5/52.20000000000003 (-40.70000000000003)\n",
      "Epoch 003/051 | Loss 0.0085 | Win/lose count 13.0/40.60000000000004 (-27.600000000000037)\n",
      "Epoch 004/051 | Loss 0.0104 | Win/lose count 11.0/61.10000000000001 (-50.10000000000001)\n",
      "Epoch 005/051 | Loss 0.0096 | Win/lose count 11.0/37.70000000000004 (-26.70000000000004)\n",
      "Epoch 006/051 | Loss 0.0091 | Win/lose count 16.5/33.50000000000004 (-17.000000000000043)\n",
      "Epoch 007/051 | Loss 0.0065 | Win/lose count 16.5/40.10000000000002 (-23.600000000000023)\n",
      "Epoch 008/051 | Loss 0.0072 | Win/lose count 14.5/37.000000000000014 (-22.500000000000014)\n",
      "Epoch 009/051 | Loss 0.0154 | Win/lose count 13.0/33.60000000000001 (-20.60000000000001)\n",
      "Epoch 010/051 | Loss 0.0148 | Win/lose count 21.5/32.00000000000003 (-10.500000000000028)\n",
      "Epoch 011/051 | Loss 0.0384 | Win/lose count 11.0/40.80000000000002 (-29.80000000000002)\n",
      "Epoch 012/051 | Loss 0.0099 | Win/lose count 18.0/37.50000000000003 (-19.50000000000003)\n",
      "Epoch 013/051 | Loss 0.0147 | Win/lose count 13.5/38.400000000000034 (-24.900000000000034)\n",
      "Epoch 014/051 | Loss 0.0066 | Win/lose count 12.0/28.90000000000002 (-16.90000000000002)\n",
      "Epoch 015/051 | Loss 0.0059 | Win/lose count 17.0/38.90000000000005 (-21.90000000000005)\n",
      "Epoch 016/051 | Loss 0.0086 | Win/lose count 14.5/31.900000000000023 (-17.400000000000023)\n",
      "Epoch 017/051 | Loss 0.0100 | Win/lose count 14.5/35.600000000000016 (-21.100000000000016)\n",
      "Epoch 018/051 | Loss 0.0083 | Win/lose count 14.0/42.40000000000003 (-28.400000000000027)\n",
      "Epoch 019/051 | Loss 0.0091 | Win/lose count 11.5/42.9 (-31.4)\n",
      "Epoch 020/051 | Loss 0.0104 | Win/lose count 14.5/37.300000000000054 (-22.800000000000054)\n",
      "Epoch 021/051 | Loss 0.0062 | Win/lose count 7.5/66.19999999999999 (-58.69999999999999)\n",
      "Epoch 022/051 | Loss 0.0080 | Win/lose count 13.5/31.200000000000017 (-17.700000000000017)\n",
      "Epoch 023/051 | Loss 0.0105 | Win/lose count 13.0/29.300000000000022 (-16.300000000000022)\n",
      "Epoch 024/051 | Loss 0.0084 | Win/lose count 14.0/31.600000000000026 (-17.600000000000026)\n",
      "Epoch 025/051 | Loss 0.0085 | Win/lose count 16.5/41.70000000000003 (-25.20000000000003)\n",
      "Epoch 026/051 | Loss 0.0089 | Win/lose count 16.0/30.7 (-14.7)\n",
      "Epoch 027/051 | Loss 0.0086 | Win/lose count 12.0/31.40000000000002 (-19.40000000000002)\n",
      "Epoch 028/051 | Loss 0.0143 | Win/lose count 14.0/40.400000000000034 (-26.400000000000034)\n",
      "Epoch 029/051 | Loss 0.0094 | Win/lose count 14.5/31.000000000000014 (-16.500000000000014)\n",
      "Epoch 030/051 | Loss 0.0103 | Win/lose count 16.0/30.800000000000008 (-14.800000000000008)\n",
      "Epoch 031/051 | Loss 0.0064 | Win/lose count 17.5/29.50000000000003 (-12.000000000000028)\n",
      "Epoch 032/051 | Loss 0.0073 | Win/lose count 10.5/38.20000000000002 (-27.700000000000017)\n",
      "Epoch 033/051 | Loss 0.0067 | Win/lose count 18.0/31.600000000000023 (-13.600000000000023)\n",
      "Epoch 034/051 | Loss 0.0073 | Win/lose count 17.5/25.20000000000003 (-7.700000000000031)\n",
      "Epoch 035/051 | Loss 0.0064 | Win/lose count 14.0/33.100000000000016 (-19.100000000000016)\n",
      "Epoch 036/051 | Loss 0.0091 | Win/lose count 13.5/31.90000000000003 (-18.40000000000003)\n",
      "Epoch 037/051 | Loss 0.0071 | Win/lose count 17.5/28.400000000000016 (-10.900000000000016)\n",
      "Epoch 038/051 | Loss 0.0068 | Win/lose count 13.0/42.70000000000004 (-29.70000000000004)\n",
      "Epoch 039/051 | Loss 0.0122 | Win/lose count 13.5/32.20000000000002 (-18.700000000000017)\n",
      "Epoch 040/051 | Loss 0.0083 | Win/lose count 9.5/46.100000000000016 (-36.600000000000016)\n",
      "Epoch 041/051 | Loss 0.0095 | Win/lose count 15.0/30.00000000000002 (-15.000000000000021)\n",
      "Epoch 042/051 | Loss 0.0178 | Win/lose count 15.5/42.80000000000003 (-27.300000000000033)\n",
      "Epoch 043/051 | Loss 0.0124 | Win/lose count 19.0/31.700000000000028 (-12.700000000000028)\n",
      "Epoch 044/051 | Loss 0.0077 | Win/lose count 17.5/33.60000000000004 (-16.100000000000037)\n",
      "Epoch 045/051 | Loss 0.0066 | Win/lose count 19.0/30.40000000000002 (-11.40000000000002)\n",
      "Epoch 046/051 | Loss 0.0275 | Win/lose count 10.5/38.60000000000003 (-28.10000000000003)\n",
      "Epoch 047/051 | Loss 0.0082 | Win/lose count 10.5/41.8 (-31.299999999999997)\n",
      "Epoch 048/051 | Loss 0.0093 | Win/lose count 15.0/33.400000000000034 (-18.400000000000034)\n",
      "Epoch 049/051 | Loss 0.0085 | Win/lose count 12.0/32.40000000000002 (-20.40000000000002)\n",
      "Epoch 050/051 | Loss 0.0081 | Win/lose count 16.0/30.7 (-14.7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent = DQN_CNN(size, lr=.001, epsilon = 0.9, memory_size=2000, batch_size = 32,n_state=3)\n",
    "train_explore(agent, env, 51, epsilon_start=0.7, epsilon_end=0.1, \n",
    "              epsilon_decay=60000, prefix='cnn_train_explore')\n",
    "HTML(display_videos('cnn_train_explore50.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win/lose count 21.5/4.0. Average score (17.5)\n",
      "Win/lose count 19.5/3.0. Average score (17.0)\n",
      "Win/lose count 23.0/3.0. Average score (18.0)\n",
      "Win/lose count 20.5/4.0. Average score (17.625)\n",
      "Win/lose count 18.0/5.0. Average score (16.7)\n",
      "Win/lose count 27.5/3.0. Average score (18.0)\n",
      "Win/lose count 19.5/5.0. Average score (17.5)\n",
      "Win/lose count 22.5/6.0. Average score (17.375)\n",
      "Win/lose count 21.5/3.0. Average score (17.5)\n",
      "Win/lose count 18.0/1.0. Average score (17.45)\n",
      "Win/lose count 20.5/2.0. Average score (17.545454545454547)\n",
      "Win/lose count 19.0/2.0. Average score (17.5)\n",
      "Win/lose count 22.5/5.0. Average score (17.5)\n",
      "Win/lose count 21.5/0. Average score (17.785714285714285)\n",
      "Win/lose count 20.0/3.0. Average score (17.733333333333334)\n",
      "Win/lose count 21.0/2.0. Average score (17.8125)\n",
      "Win/lose count 25.0/5.0. Average score (17.941176470588236)\n",
      "Win/lose count 14.0/5.0. Average score (17.444444444444443)\n",
      "Win/lose count 20.5/5.0. Average score (17.342105263157894)\n",
      "Win/lose count 21.5/3.0. Average score (17.4)\n",
      "Win/lose count 23.5/4.0. Average score (17.5)\n",
      "Final score: 17.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation\n",
    "test(agent,env,21,prefix='cnn_test_explore')\n",
    "HTML(display_videos('cnn_test_explore0.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(agent, env, size):\n",
    "    states = []\n",
    "    actions = []\n",
    "        \n",
    "    while len(states) < size:\n",
    "        \n",
    "        # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will end\n",
    "        game_over = False\n",
    "\n",
    "        while not game_over:\n",
    "            # The agent performs an action\n",
    "            action = agent.act(state, train=False)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action)\n",
    "            onehot_action = [0, 0, 0, 0]\n",
    "            onehot_action[action] = 1\n",
    "            if len(states) < size and reward > 0:  # only keep wining examples\n",
    "                states.append(prev_state)\n",
    "                actions.append(onehot_action)\n",
    "    return np.array(states), np.array(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, target_train = build_dataset(agent, env, size=5000)\n",
    "dataset_test, target_test = build_dataset(agent, env, size=100)\n",
    "dataset_val, target_val = build_dataset(agent, env, size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Reshape((-1,), input_shape=(5,5,3)))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dense(4, activation=\"softmax\"))\n",
    "\n",
    "model.compile(Adam(lr=0.01, beta_1=0.9, beta_2=0.999), \"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5000 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "5000/5000 [==============================] - 1s 169us/step - loss: 0.0666 - val_loss: 0.0457\n",
      "Epoch 2/50\n",
      "5000/5000 [==============================] - 0s 31us/step - loss: 0.0265 - val_loss: 0.0404\n",
      "Epoch 3/50\n",
      "5000/5000 [==============================] - 0s 33us/step - loss: 0.0248 - val_loss: 0.0413\n",
      "Epoch 4/50\n",
      "5000/5000 [==============================] - 0s 37us/step - loss: 0.0231 - val_loss: 0.0433\n",
      "Epoch 5/50\n",
      "5000/5000 [==============================] - 0s 33us/step - loss: 0.0204 - val_loss: 0.0397\n",
      "Epoch 6/50\n",
      "5000/5000 [==============================] - 0s 36us/step - loss: 0.0196 - val_loss: 0.0373\n",
      "Epoch 7/50\n",
      "5000/5000 [==============================] - 0s 29us/step - loss: 0.0177 - val_loss: 0.0380\n",
      "Epoch 8/50\n",
      "5000/5000 [==============================] - 0s 37us/step - loss: 0.0170 - val_loss: 0.0333\n",
      "Epoch 9/50\n",
      "5000/5000 [==============================] - 0s 30us/step - loss: 0.0145 - val_loss: 0.0363\n",
      "Epoch 10/50\n",
      "5000/5000 [==============================] - 0s 26us/step - loss: 0.0132 - val_loss: 0.0324\n",
      "Epoch 11/50\n",
      "5000/5000 [==============================] - 0s 28us/step - loss: 0.0118 - val_loss: 0.0331\n",
      "Epoch 12/50\n",
      "5000/5000 [==============================] - 0s 34us/step - loss: 0.0113 - val_loss: 0.0410\n",
      "Epoch 13/50\n",
      "5000/5000 [==============================] - 0s 34us/step - loss: 0.0114 - val_loss: 0.0302\n",
      "Epoch 14/50\n",
      "5000/5000 [==============================] - 0s 27us/step - loss: 0.0108 - val_loss: 0.0365\n",
      "Epoch 15/50\n",
      "5000/5000 [==============================] - 0s 36us/step - loss: 0.0097 - val_loss: 0.0362\n",
      "Epoch 16/50\n",
      "5000/5000 [==============================] - 0s 37us/step - loss: 0.0086 - val_loss: 0.0394\n",
      "Epoch 17/50\n",
      "5000/5000 [==============================] - 0s 28us/step - loss: 0.0100 - val_loss: 0.0344\n",
      "Epoch 18/50\n",
      "5000/5000 [==============================] - 0s 34us/step - loss: 0.0097 - val_loss: 0.0372\n",
      "Epoch 19/50\n",
      "5000/5000 [==============================] - 0s 34us/step - loss: 0.0105 - val_loss: 0.0340\n",
      "Epoch 20/50\n",
      "5000/5000 [==============================] - 0s 34us/step - loss: 0.0108 - val_loss: 0.0443\n",
      "Epoch 21/50\n",
      "5000/5000 [==============================] - 0s 37us/step - loss: 0.0087 - val_loss: 0.0464\n",
      "Epoch 22/50\n",
      "5000/5000 [==============================] - 0s 35us/step - loss: 0.0077 - val_loss: 0.0500\n",
      "Epoch 23/50\n",
      "5000/5000 [==============================] - 0s 33us/step - loss: 0.0067 - val_loss: 0.0439\n",
      "Epoch 24/50\n",
      "5000/5000 [==============================] - 0s 34us/step - loss: 0.0066 - val_loss: 0.0427\n",
      "Epoch 25/50\n",
      "5000/5000 [==============================] - 0s 35us/step - loss: 0.0071 - val_loss: 0.0347\n",
      "Epoch 26/50\n",
      "5000/5000 [==============================] - 0s 36us/step - loss: 0.0068 - val_loss: 0.0350\n",
      "Epoch 27/50\n",
      "5000/5000 [==============================] - 0s 28us/step - loss: 0.0066 - val_loss: 0.0427\n",
      "Epoch 28/50\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.0052 - val_loss: 0.0370\n",
      "Epoch 29/50\n",
      "5000/5000 [==============================] - 0s 27us/step - loss: 0.0054 - val_loss: 0.0371\n",
      "Epoch 30/50\n",
      "5000/5000 [==============================] - 0s 37us/step - loss: 0.0054 - val_loss: 0.0340\n",
      "Epoch 31/50\n",
      "5000/5000 [==============================] - 0s 36us/step - loss: 0.0078 - val_loss: 0.0296\n",
      "Epoch 32/50\n",
      "5000/5000 [==============================] - 0s 33us/step - loss: 0.0092 - val_loss: 0.0463\n",
      "Epoch 33/50\n",
      "5000/5000 [==============================] - 0s 28us/step - loss: 0.0111 - val_loss: 0.0268\n",
      "Epoch 34/50\n",
      "5000/5000 [==============================] - 0s 36us/step - loss: 0.0088 - val_loss: 0.0400\n",
      "Epoch 35/50\n",
      "5000/5000 [==============================] - 0s 36us/step - loss: 0.0114 - val_loss: 0.0471\n",
      "Epoch 36/50\n",
      "5000/5000 [==============================] - 0s 29us/step - loss: 0.0098 - val_loss: 0.0435\n",
      "Epoch 37/50\n",
      "5000/5000 [==============================] - 0s 34us/step - loss: 0.0070 - val_loss: 0.0367\n",
      "Epoch 38/50\n",
      "5000/5000 [==============================] - 0s 32us/step - loss: 0.0081 - val_loss: 0.0486\n",
      "Epoch 39/50\n",
      "5000/5000 [==============================] - 0s 32us/step - loss: 0.0075 - val_loss: 0.0352\n",
      "Epoch 40/50\n",
      "5000/5000 [==============================] - 0s 31us/step - loss: 0.0065 - val_loss: 0.0472\n",
      "Epoch 41/50\n",
      "5000/5000 [==============================] - 0s 34us/step - loss: 0.0071 - val_loss: 0.0514\n",
      "Epoch 42/50\n",
      "5000/5000 [==============================] - 0s 30us/step - loss: 0.0095 - val_loss: 0.0556\n",
      "Epoch 43/50\n",
      "5000/5000 [==============================] - 0s 35us/step - loss: 0.0072 - val_loss: 0.0415\n",
      "Epoch 44/50\n",
      "5000/5000 [==============================] - 0s 31us/step - loss: 0.0086 - val_loss: 0.0347\n",
      "Epoch 45/50\n",
      "5000/5000 [==============================] - 0s 31us/step - loss: 0.0082 - val_loss: 0.0423\n",
      "Epoch 46/50\n",
      "5000/5000 [==============================] - 0s 30us/step - loss: 0.0083 - val_loss: 0.0495\n",
      "Epoch 47/50\n",
      "5000/5000 [==============================] - 0s 31us/step - loss: 0.0089 - val_loss: 0.0444\n",
      "Epoch 48/50\n",
      "5000/5000 [==============================] - 0s 31us/step - loss: 0.0090 - val_loss: 0.0414\n",
      "Epoch 49/50\n",
      "5000/5000 [==============================] - 0s 27us/step - loss: 0.0067 - val_loss: 0.0325\n",
      "Epoch 50/50\n",
      "5000/5000 [==============================] - 0s 35us/step - loss: 0.0074 - val_loss: 0.0353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f86c3a5beb8>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dataset_train, target_train, batch_size=64, validation_data=(dataset_val, target_val), epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(agent, env, epochs, prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "        \n",
    "    for e in range(epochs):\n",
    "        \n",
    "         # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will end\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "\n",
    "        while not game_over:\n",
    "            # The agent performs an action\n",
    "            action = agent.predict(np.expand_dims(state, axis=0))[0].argmax()\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "        \n",
    "        # Save as a mp4\n",
    "        env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score = score + win-lose\n",
    "\n",
    "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
    "              .format(win, lose, score/(1+e)))\n",
    "    print('Final score: '+str(score/epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win/lose count 20.5/3.0. Average score (17.5)\n",
      "Win/lose count 19.0/2.0. Average score (17.25)\n",
      "Win/lose count 22.5/2.0. Average score (18.333333333333332)\n",
      "Win/lose count 18.0/3.0. Average score (17.5)\n",
      "Win/lose count 22.0/2.0. Average score (18.0)\n",
      "Win/lose count 26.0/2.0. Average score (19.0)\n",
      "Win/lose count 25.5/2.0. Average score (19.642857142857142)\n",
      "Win/lose count 18.5/0. Average score (19.5)\n",
      "Win/lose count 23.0/3.0. Average score (19.555555555555557)\n",
      "Win/lose count 22.5/0. Average score (19.85)\n",
      "Win/lose count 17.5/4.0. Average score (19.272727272727273)\n",
      "Win/lose count 24.0/0. Average score (19.666666666666668)\n",
      "Win/lose count 27.0/2.0. Average score (20.076923076923077)\n",
      "Win/lose count 17.5/1.0. Average score (19.821428571428573)\n",
      "Win/lose count 25.5/4.0. Average score (19.933333333333334)\n",
      "Win/lose count 19.0/2.0. Average score (19.75)\n",
      "Win/lose count 20.5/1.0. Average score (19.735294117647058)\n",
      "Win/lose count 23.5/2.0. Average score (19.833333333333332)\n",
      "Win/lose count 22.0/3.0. Average score (19.789473684210527)\n",
      "Win/lose count 18.5/3.0. Average score (19.575)\n",
      "Win/lose count 20.0/3.0. Average score (19.452380952380953)\n",
      "Final score: 19.452380952380953\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, env, 21, prefix=\"nonrl_test\")\n",
    "HTML(display_videos('nonrl_test0.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We observe that the final score is better than in the RL method and we only use a fully connected network (without convolution layers).\n",
    "> This is because this network has only seen the successful actions of the RL trained model. Moreover, it is much faster to train. Indeed, we need much less data to train this model for it to understand the goal of the game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
